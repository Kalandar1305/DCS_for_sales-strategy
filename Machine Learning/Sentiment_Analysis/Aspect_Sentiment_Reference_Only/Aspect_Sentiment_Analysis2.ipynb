{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, SpatialDropout1D, LSTM, Dense, Lambda, Activation, Multiply, Concatenate, RepeatVector, Flatten, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Laptop_Train_v2.csv', encoding='latin1').dropna()\n",
    "df = df[['text', 'term', 'polarity']]\n",
    "df.drop(df[df['polarity'] == 'conflict'].index, inplace = True)\n",
    "# Preprocessing: Tokenization, stopword removal, and lowercase conversion\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = tokenizer.tokenize(text.lower())\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "df['processed_text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>term</th>\n",
       "      <th>polarity</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I charge it at night and skip taking the cord ...</td>\n",
       "      <td>cord</td>\n",
       "      <td>neutral</td>\n",
       "      <td>charge night skip taking cord good battery life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I charge it at night and skip taking the cord ...</td>\n",
       "      <td>battery life</td>\n",
       "      <td>positive</td>\n",
       "      <td>charge night skip taking cord good battery life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>service center</td>\n",
       "      <td>negative</td>\n",
       "      <td>tech guy said service center 1 1 exchange dire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>\"sales\" team</td>\n",
       "      <td>negative</td>\n",
       "      <td>tech guy said service center 1 1 exchange dire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>tech guy</td>\n",
       "      <td>neutral</td>\n",
       "      <td>tech guy said service center 1 1 exchange dire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>We also use Paralles so we can run virtual mac...</td>\n",
       "      <td>Windows 7 Home Premium</td>\n",
       "      <td>neutral</td>\n",
       "      <td>also use paralles run virtual machines windows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>We also use Paralles so we can run virtual mac...</td>\n",
       "      <td>Windows Server Enterprise 2003</td>\n",
       "      <td>neutral</td>\n",
       "      <td>also use paralles run virtual machines windows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3900</th>\n",
       "      <td>We also use Paralles so we can run virtual mac...</td>\n",
       "      <td>Windows Server 2008 Enterprise</td>\n",
       "      <td>neutral</td>\n",
       "      <td>also use paralles run virtual machines windows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3906</th>\n",
       "      <td>How Toshiba handles the repair seems to vary, ...</td>\n",
       "      <td>repair</td>\n",
       "      <td>positive</td>\n",
       "      <td>toshiba handles repair seems vary folks indica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3907</th>\n",
       "      <td>I would like to use a different operating syst...</td>\n",
       "      <td>operating system</td>\n",
       "      <td>neutral</td>\n",
       "      <td>would like use different operating system alto...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2313 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     I charge it at night and skip taking the cord ...   \n",
       "1     I charge it at night and skip taking the cord ...   \n",
       "3     The tech guy then said the service center does...   \n",
       "4     The tech guy then said the service center does...   \n",
       "5     The tech guy then said the service center does...   \n",
       "...                                                 ...   \n",
       "3898  We also use Paralles so we can run virtual mac...   \n",
       "3899  We also use Paralles so we can run virtual mac...   \n",
       "3900  We also use Paralles so we can run virtual mac...   \n",
       "3906  How Toshiba handles the repair seems to vary, ...   \n",
       "3907  I would like to use a different operating syst...   \n",
       "\n",
       "                                term  polarity  \\\n",
       "0                               cord   neutral   \n",
       "1                       battery life  positive   \n",
       "3                     service center  negative   \n",
       "4                       \"sales\" team  negative   \n",
       "5                           tech guy   neutral   \n",
       "...                              ...       ...   \n",
       "3898          Windows 7 Home Premium   neutral   \n",
       "3899  Windows Server Enterprise 2003   neutral   \n",
       "3900  Windows Server 2008 Enterprise   neutral   \n",
       "3906                          repair  positive   \n",
       "3907                operating system   neutral   \n",
       "\n",
       "                                         processed_text  \n",
       "0       charge night skip taking cord good battery life  \n",
       "1       charge night skip taking cord good battery life  \n",
       "3     tech guy said service center 1 1 exchange dire...  \n",
       "4     tech guy said service center 1 1 exchange dire...  \n",
       "5     tech guy said service center 1 1 exchange dire...  \n",
       "...                                                 ...  \n",
       "3898  also use paralles run virtual machines windows...  \n",
       "3899  also use paralles run virtual machines windows...  \n",
       "3900  also use paralles run virtual machines windows...  \n",
       "3906  toshiba handles repair seems vary folks indica...  \n",
       "3907  would like use different operating system alto...  \n",
       "\n",
       "[2313 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text              object\n",
      "term              object\n",
      "polarity          object\n",
      "processed_text    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "max_len = 128\n",
    "text_tokenizer = Tokenizer(num_words=10000)\n",
    "text_tokenizer.fit_on_texts(df['processed_text'])\n",
    "text_sequences = text_tokenizer.texts_to_sequences(df['processed_text'])\n",
    "text_sequences = pad_sequences(text_sequences, maxlen=max_len)\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text and aspect terms\n",
    "\n",
    "aspect_tokenizer = Tokenizer(num_words=100)\n",
    "aspect_tokenizer.fit_on_texts(df['term'].astype(str))\n",
    "aspect_sequences = aspect_tokenizer.texts_to_sequences(df['term'])\n",
    "aspect_sequences = pad_sequences(aspect_sequences, maxlen=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        neutral\n",
       "1       positive\n",
       "3       negative\n",
       "4       negative\n",
       "5        neutral\n",
       "          ...   \n",
       "3898     neutral\n",
       "3899     neutral\n",
       "3900     neutral\n",
       "3906    positive\n",
       "3907     neutral\n",
       "Name: polarity, Length: 2313, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_size = int(len(df) * 0.8)\n",
    "train_text = text_sequences[:train_size]\n",
    "train_aspect = aspect_sequences[:train_size]\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoder.fit(np.array(df['polarity']).reshape(-1,1))\n",
    "train_labels = encoder.transform(np.array(df['polarity'][:train_size]).reshape(-1,1))\n",
    "test_text = text_sequences[train_size:]\n",
    "test_aspect = aspect_sequences[train_size:]\n",
    "test_labels = encoder.transform(np.array(df['polarity'][train_size:]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "text_input = Input(shape=(max_len,))\n",
    "aspect_input = Input(shape=(1,))\n",
    "embedding = Embedding(input_dim=10000, output_dim=128, input_length=max_len)(text_input)\n",
    "dropout = SpatialDropout1D(0.2)(embedding)\n",
    "lstm = LSTM(128, return_sequences=True)(dropout)\n",
    "attention = Dense(1, activation='tanh')(lstm)\n",
    "attention = Flatten()(attention)\n",
    "attention = Reshape((128, 1))(attention)  # Reshape the attention tensor\n",
    "attention = Multiply()([attention, RepeatVector(max_len)(aspect_input)])\n",
    "attention = Activation('softmax')(attention)\n",
    "context = Multiply()([lstm, attention])\n",
    "context = Lambda(lambda x: K.sum(x, axis=1))(context)\n",
    "merged = Concatenate(axis=1)([context, aspect_input])\n",
    "output = Dense(3, activation='softmax')(merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "10/10 [==============================] - 4s 107ms/step - loss: 0.1688 - accuracy: 0.8989 - val_loss: 1.9581 - val_accuracy: 0.5875\n",
      "Epoch 2/15\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.1621 - accuracy: 0.9124 - val_loss: 1.8704 - val_accuracy: 0.5767\n",
      "Epoch 3/15\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.1560 - accuracy: 0.9076 - val_loss: 1.9090 - val_accuracy: 0.5853\n",
      "Epoch 4/15\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.1541 - accuracy: 0.9189 - val_loss: 1.9217 - val_accuracy: 0.6156\n",
      "Epoch 5/15\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.1555 - accuracy: 0.9162 - val_loss: 1.9337 - val_accuracy: 0.5745\n",
      "Epoch 6/15\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.1482 - accuracy: 0.9200 - val_loss: 1.9770 - val_accuracy: 0.5961\n",
      "Epoch 7/15\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.1438 - accuracy: 0.9157 - val_loss: 1.9657 - val_accuracy: 0.5961\n",
      "Epoch 8/15\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.1462 - accuracy: 0.9146 - val_loss: 1.9812 - val_accuracy: 0.5896\n",
      "Epoch 9/15\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.1468 - accuracy: 0.9216 - val_loss: 2.0020 - val_accuracy: 0.5875\n",
      "Epoch 10/15\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.1475 - accuracy: 0.9178 - val_loss: 2.0456 - val_accuracy: 0.5918\n",
      "Epoch 11/15\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.1489 - accuracy: 0.9173 - val_loss: 2.0990 - val_accuracy: 0.5940\n",
      "Epoch 12/15\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.1477 - accuracy: 0.9108 - val_loss: 2.0226 - val_accuracy: 0.5832\n",
      "Epoch 13/15\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.1505 - accuracy: 0.9151 - val_loss: 2.0415 - val_accuracy: 0.5810\n",
      "Epoch 14/15\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.1614 - accuracy: 0.9065 - val_loss: 2.0884 - val_accuracy: 0.5983\n",
      "Epoch 15/15\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.1507 - accuracy: 0.9151 - val_loss: 2.0980 - val_accuracy: 0.5961\n",
      "Test accuracy: 0.5961123108863831\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Model(inputs=[text_input, aspect_input], outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit([train_text, train_aspect], train_labels, validation_data=([test_text, test_aspect], test_labels), epochs=15, batch_size=200)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate([test_text, test_aspect], test_labels, verbose=0)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentances = [\"The battery is good. But the processor is bit slow than what i expected.\",\"The battery is good. But the performance is very slow than what i expected.\"]\n",
    "aspects = ['battery', 'processor']\n",
    "sentance_tokenized = text_tokenizer.texts_to_sequences(sentances) # list of tokenized sentences\n",
    "Aspect_X_train_tokenized = aspect_tokenizer.texts_to_sequences(aspects) # list of tokenized sentences\n",
    "\n",
    "text_X_train_padded = pad_sequences(sentance_tokenized, maxlen=max_len)\n",
    "aspect_X_train_padded = pad_sequences(Aspect_X_train_tokenized, maxlen=1)\n",
    "\n",
    "sample = [text_X_train_padded, aspect_X_train_padded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['negative'],\n",
       "       ['negative']], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inverse_transform(model.predict(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
