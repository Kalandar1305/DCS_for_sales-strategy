{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, GRU, SimpleRNN, Embedding\n",
    "from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bbc.csv')\n",
    "df.head()\n",
    "df['targets'] = df['labels'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=df['targets'].max()+1\n",
    "\n",
    "df_train,df_test=train_test_split(df,test_size=0.3)\n",
    "\n",
    "MAX_VOCAB_SIZE=2000\n",
    "tokenizer=Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(df_train['text'])\n",
    "\n",
    "sequences_train = tokenizer.texts_to_sequences(df_train['text'])\n",
    "sequences_test  = tokenizer.texts_to_sequences(df_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = tokenizer.word_index\n",
    "V = len(word2idx)\n",
    "print(\"Unique tokens: \", V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=pad_sequences(sequences_train)\n",
    "print(\"Shape of the data train tensor\",data_train.shape)\n",
    "T=data_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=pad_sequences(sequences_test, maxlen=T)\n",
    "print(\"Shape of the data train tensor\",data_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 20\n",
    "\n",
    "i = Input(shape = (T,))\n",
    "x = Embedding(V+1, D) (i)\n",
    "x = LSTM(32, return_sequences=True)(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(K)(x)\n",
    "model = Model(i, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=\"adam\",\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Training Model\")\n",
    "\n",
    "r = model.fit(\n",
    "    data_train,\n",
    "    df_train['targets'],\n",
    "    epochs = 50,\n",
    "    validation_data=(data_test, df_test['targets'])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(r.history['loss'], label = 'train loss')\n",
    "plt.plot(r.history['val_loss'], label = 'val loss')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
