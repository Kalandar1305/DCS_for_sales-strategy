{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e06e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "935253d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "656c7433",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Sentiment Analysis_Remote\") \\\n",
    "    .master('spark://0.0.0.0:7077') \\\n",
    "    .config(\"spark.executor.resource.gpu.amount\", \"1\") \\\n",
    "    .config(\"spark.rapids.sql.enabled\", \"true\") \\\n",
    "    .config(\"spark.plugins\", \"com.nvidia.spark.SQLPlugin\") \\\n",
    "    .config(\"spark.executor.memory\", \"25g\")\\\n",
    "    .config(\"spark.shuffle.service.enabled\", \"false\")\\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"false\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9fa2bd3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://a8fb7ade9567:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://0.0.0.0:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Sentiment Analysis_Remote</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f7a14ab9b50>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24a12834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- Review: string (nullable = true)\n",
      " |-- Summary: string (nullable = true)\n",
      " |-- Sentiment: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"datasets/sentiment_data_trim.csv\", header=True, inferSchema=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5fea8444",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"_c0\")\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d543e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws\n",
    "df = df.withColumn(\"Reviews\", concat_ws(\" \", df.Review, df.Summary))\n",
    "df = df.drop(\"Review\", \"Summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9da2aed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3119c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql.types import IntegerType\n",
    "# df = df.withColumn(\"Sentiment\", df[\"Sentiment\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "afa9cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove special characters and numbers from the reviews\n",
    "import re\n",
    "from pyspark.sql.functions import udf\n",
    "def removeSpecChar(raw_text):\n",
    "    print(type(raw_text))\n",
    "    clean_SpecialChar = re.sub(\"[^a-zA-Z]\", \" \", raw_text)  \n",
    "    return clean_SpecialChar\n",
    "removeSpecialChar = udf(removeSpecChar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b846a438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower\n",
    "df = df.withColumn(\"Reviews\", removeSpecialChar(lower(df[\"Reviews\"])))\n",
    "# df.show(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2897a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"Reviews\", outputCol=\"reviewtoken\")\n",
    "df = tokenizer.transform(df)\n",
    "# df.show(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06defc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from nltk.corpus import stopwords\n",
    "remover = StopWordsRemover(inputCol=\"reviewtoken\", outputCol=\"reviewtokenfiltered\", stopWords=stopwords.words(\"english\"))\n",
    "df = remover.transform(df)\n",
    "# df.show(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1da7435e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Sentiment: integer (nullable = true)\n",
      " |-- Reviews: string (nullable = true)\n",
      " |-- reviewtoken: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- reviewtokenfiltered: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb06c01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "def get_wordnet_pos(tag):\n",
    "    from nltk.corpus import wordnet\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else: \n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c66176c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatizeScalar(sentance):\n",
    "    from nltk.tag import pos_tag\n",
    "    print(sentance)\n",
    "    tagged = pos_tag( [i for i in sentance if i])\n",
    "    lemmatized = []\n",
    "    for word, tag in tagged:\n",
    "        lemma = lemmatizer.lemmatize(word, pos = get_wordnet_pos(tag))\n",
    "        lemmatized.append(lemma)\n",
    "    return lemmatized\n",
    "lemmatize = udf(lemmatizeScalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "82b07645",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"reviewtokenfiltered2\", lemmatize(df.reviewtokenfiltered))\n",
    "# dfnew.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bc27e727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "df = df.withColumn('reviewtokenfiltered2', expr(r\"regexp_extract_all(reviewtokenfiltered2, '(\\\\w+)', 1)\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d7d5938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"reviewtoken\", \"Reviews\",\"reviewtokenfiltered\")\n",
    "df = df.withColumnRenamed(\"reviewtokenfiltered2\", \"reviewtokenfiltered\")\n",
    "# df.show(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "245ef033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Sentiment: integer (nullable = true)\n",
      " |-- reviewtokenfiltered: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0405d84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = df.randomSplit([0.6,0.2,0.2], seed=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756a2bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "hashingTF = HashingTF(inputCol=\"reviewtokenfiltered\", outputCol=\"termFrequency\", numFeatures=37120)\n",
    "split[0] = hashingTF.transform(split[0])\n",
    "# split[0].show(n=2)\n",
    "\n",
    "idf = IDF(inputCol=\"termFrequency\", outputCol=\"features\", )\n",
    "idfModel = idf.fit(split[0])\n",
    "split[0] = idfModel.transform(split[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd00e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IDFModel: uid=IDF_cf19aebc35ba, numDocs=174944, numFeatures=37120"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8984c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "split[1] = hashingTF.transform(split[1])\n",
    "split[2] = hashingTF.transform(split[2])\n",
    "# split[1].show(n=2)\n",
    "\n",
    "split[1] = idfModel.transform(split[1])\n",
    "split[2] = idfModel.transform(split[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f0a2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+--------------------+\n",
      "|Sentiment| reviewtokenfiltered|       termFrequency|            features|\n",
      "+---------+--------------------+--------------------+--------------------+\n",
      "|        0|[absolute, rubbis...|(37120,[6205,1763...|(37120,[6205,1763...|\n",
      "|        0|[absolute, rubbis...|(37120,[6205,1763...|(37120,[6205,1763...|\n",
      "|        0|[absolute, rubbis...|(37120,[6205,1763...|(37120,[6205,1763...|\n",
      "|        0|[absolute, rubbis...|(37120,[6205,1763...|(37120,[6205,1763...|\n",
      "|        0|[absolute, rubbis...|(37120,[6205,1763...|(37120,[6205,1763...|\n",
      "|        0|[absolute, rubbis...|(37120,[6205,1763...|(37120,[6205,1763...|\n",
      "|        0|[absolute, rubbis...|(37120,[3267,4322...|(37120,[3267,4322...|\n",
      "|        0|[absolute, rubbis...|(37120,[6205,1763...|(37120,[6205,1763...|\n",
      "|        0|[absolute, rubbis...|(37120,[5181,6205...|(37120,[5181,6205...|\n",
      "|        0|[absolute, rubbis...|(37120,[6205,1396...|(37120,[6205,1396...|\n",
      "|        0|[absolute, rubbis...|(37120,[6205,1396...|(37120,[6205,1396...|\n",
      "|        0|[absolute, rubbis...|(37120,[6205,1396...|(37120,[6205,1396...|\n",
      "|        0|[absolute, rubbis...|(37120,[6205,1396...|(37120,[6205,1396...|\n",
      "|        0|[absolute, rubbis...|(37120,[6205,1396...|(37120,[6205,1396...|\n",
      "|        0|[absolute, rubbis...|(37120,[6205,1396...|(37120,[6205,1396...|\n",
      "|        0|[absolute, rubbis...|(37120,[6205,1396...|(37120,[6205,1396...|\n",
      "|        0|[absolute, rubbis...|(37120,[2103,6205...|(37120,[2103,6205...|\n",
      "|        0|[absolute, rubbis...|(37120,[4400,5993...|(37120,[4400,5993...|\n",
      "|        0|[absolute, rubbis...|(37120,[6006,6205...|(37120,[6006,6205...|\n",
      "|        0|[absolute, rubbis...|(37120,[6205,1396...|(37120,[6205,1396...|\n",
      "+---------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split[1].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17673bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = split[0].select('features', 'sentiment')\n",
    "test = split[1].select('features', 'sentiment')\n",
    "validation = split[2].select('features', 'sentiment')\n",
    "\n",
    "train = train.withColumnRenamed('sentiment', 'label')\n",
    "test = test.withColumnRenamed('sentiment', 'label')\n",
    "validation = validation.withColumnRenamed('sentiment', 'label')\n",
    "\n",
    "# train.show(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fb5272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "lrModel = lr.fit(train)\n",
    "\n",
    "LogisticRegressionModel.save(lrModel, \"LinearRegression_Spark2.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70658c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|(37120,[6205,1763...|    0|[-1.2923707818879...|[0.21545180171940...|       1.0|\n",
      "|(37120,[6205,1763...|    0|[-1.2923707818879...|[0.21545180171940...|       1.0|\n",
      "|(37120,[6205,1763...|    0|[-1.2923707818879...|[0.21545180171940...|       1.0|\n",
      "|(37120,[6205,1763...|    0|[-1.2923707818879...|[0.21545180171940...|       1.0|\n",
      "|(37120,[6205,1763...|    0|[-1.2923707818879...|[0.21545180171940...|       1.0|\n",
      "|(37120,[6205,1763...|    0|[-1.2923707818879...|[0.21545180171940...|       1.0|\n",
      "|(37120,[3267,4322...|    0|[-1.2923707818879...|[0.21545180171940...|       1.0|\n",
      "|(37120,[6205,1763...|    0|[-1.2923707818879...|[0.21545180171940...|       1.0|\n",
      "|(37120,[5181,6205...|    0|[-1.2923707818879...|[0.21545180171940...|       1.0|\n",
      "|(37120,[6205,1396...|    0|[-1.2923707818879...|[0.21545180171940...|       1.0|\n",
      "|(37120,[6205,1396...|    0|[-1.2923707818879...|[0.21545180171940...|       1.0|\n",
      "|(37120,[6205,1396...|    0|[-1.2923707818879...|[0.21545180171940...|       1.0|\n",
      "|(37120,[6205,1396...|    0|[-1.2923707818879...|[0.21545180171940...|       1.0|\n",
      "|(37120,[6205,1396...|    0|[-1.2923707818879...|[0.21545180171940...|       1.0|\n",
      "|(37120,[6205,1396...|    0|[-1.2923707818879...|[0.21545180171940...|       1.0|\n",
      "|(37120,[6205,1396...|    0|[-1.2923707818879...|[0.21545180171940...|       1.0|\n",
      "|(37120,[2103,6205...|    0|[-1.2923707818879...|[0.21545180171940...|       1.0|\n",
      "|(37120,[4400,5993...|    0|[-1.2923707818879...|[0.21545180171940...|       1.0|\n",
      "|(37120,[6006,6205...|    0|[-1.2923707818879...|[0.21545180171940...|       1.0|\n",
      "|(37120,[6205,1396...|    0|[-1.2923707818879...|[0.21545180171940...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lrtest = lrModel.transform(test)\n",
    "lrtest.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd05c851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6916396150555925\n",
      "Test Error = 0.30836038494440754\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(lrtest)\n",
    "print(\"Accuracy = %s\" % (accuracy))\n",
    "print(\"Test Error = %s\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b11a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pyspark/sql/context.py:157: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0. 12437.]\n",
      " [    0. 45644.]]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.types import FloatType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "preds_and_labels = lrtest.select(['prediction','label']).withColumn('label', F.col('label').cast(FloatType())).orderBy('prediction')\n",
    "preds_and_labels = preds_and_labels.select(['prediction','label'])\n",
    "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "print(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c7477d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.classification import LinearSVCModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "35d4ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "669d537d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svmModel = svm.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a8e6bbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "svmtest = svmModel.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dee34c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9753874348851735\n",
      "Test Error = 0.024612565114826457\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(svmtest)\n",
    "print(\"Accuracy = %s\" % (accuracy))\n",
    "print(\"Test Error = %s\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "74525670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pyspark/sql/context.py:157: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 34940.   2752.]\n",
      " [  1528. 135724.]]\n"
     ]
    }
   ],
   "source": [
    "preds_and_labels = svmtest.select(['prediction','label']).withColumn('label', F.col('label').cast(FloatType())).orderBy('prediction')\n",
    "preds_and_labels = preds_and_labels.select(['prediction','label'])\n",
    "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "print(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ace63f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearSVCModel.save(svmModel, \"svm_spark.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3eb10eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bbaeaf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfModel = rf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d1d1bcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassificationModel\n",
    "RandomForestClassificationModel.save(rfModel, \"RandomForest_spark.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b0f4b8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rftest = rfModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13d7006a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|(262144,[145380,2...|    0|[4.24081373896948...|[0.21204068694847...|       1.0|\n",
      "|(262144,[145380,2...|    0|[4.24081373896948...|[0.21204068694847...|       1.0|\n",
      "|(262144,[145380,2...|    0|[4.24081373896948...|[0.21204068694847...|       1.0|\n",
      "|(262144,[145380,2...|    0|[4.24081373896948...|[0.21204068694847...|       1.0|\n",
      "|(262144,[55875,14...|    0|[4.24081373896948...|[0.21204068694847...|       1.0|\n",
      "|(262144,[55875,14...|    0|[4.24081373896948...|[0.21204068694847...|       1.0|\n",
      "|(262144,[5634,258...|    0|[4.76258274092123...|[0.23812913704606...|       1.0|\n",
      "|(262144,[76764,14...|    0|[4.24081373896948...|[0.21204068694847...|       1.0|\n",
      "|(262144,[109885,1...|    0|[4.24081373896948...|[0.21204068694847...|       1.0|\n",
      "|(262144,[52879,14...|    0|[4.19317198950313...|[0.20965859947515...|       1.0|\n",
      "|(262144,[52879,14...|    0|[4.19317198950313...|[0.20965859947515...|       1.0|\n",
      "|(262144,[52879,14...|    0|[4.19317198950313...|[0.20965859947515...|       1.0|\n",
      "|(262144,[52879,14...|    0|[4.19317198950313...|[0.20965859947515...|       1.0|\n",
      "|(262144,[52879,14...|    0|[4.19317198950313...|[0.20965859947515...|       1.0|\n",
      "|(262144,[52879,14...|    0|[4.19317198950313...|[0.20965859947515...|       1.0|\n",
      "|(262144,[52879,14...|    0|[4.19317198950313...|[0.20965859947515...|       1.0|\n",
      "|(262144,[34343,52...|    0|[5.37108704402491...|[0.26855435220124...|       1.0|\n",
      "|(262144,[3564,107...|    0|[4.19317198950313...|[0.20965859947515...|       1.0|\n",
      "|(262144,[34343,52...|    0|[4.48960763531293...|[0.22448038176564...|       1.0|\n",
      "|(262144,[50880,52...|    0|[4.19317198950313...|[0.20965859947515...|       1.0|\n",
      "|(262144,[43890,52...|    0|[5.09510937761920...|[0.25475546888096...|       1.0|\n",
      "|(262144,[52879,55...|    0|[4.19317198950313...|[0.20965859947515...|       1.0|\n",
      "|(262144,[8538,394...|    0|[4.31388879040579...|[0.21569443952028...|       1.0|\n",
      "|(262144,[49908,52...|    0|[4.19317198950313...|[0.20965859947515...|       1.0|\n",
      "|(262144,[1317,528...|    0|[5.05636140058667...|[0.25281807002933...|       1.0|\n",
      "|(262144,[43890,14...|    0|[4.38409122474476...|[0.21920456123723...|       1.0|\n",
      "|(262144,[43890,14...|    0|[4.38409122474476...|[0.21920456123723...|       1.0|\n",
      "|(262144,[43890,14...|    0|[4.38409122474476...|[0.21920456123723...|       1.0|\n",
      "|(262144,[43890,52...|    0|[4.33644947527840...|[0.21682247376392...|       1.0|\n",
      "|(262144,[43890,47...|    0|[4.44097898402115...|[0.22204894920105...|       1.0|\n",
      "|(262144,[34343,14...|    0|[4.53724938477928...|[0.22686246923896...|       1.0|\n",
      "|(262144,[8538,461...|    0|[4.31388879040579...|[0.21569443952028...|       1.0|\n",
      "|(262144,[48443,75...|    0|[4.24081373896948...|[0.21204068694847...|       1.0|\n",
      "|(262144,[21823,48...|    0|[4.71176178894581...|[0.23558808944729...|       1.0|\n",
      "|(262144,[21641,76...|    0|[4.24081373896948...|[0.21204068694847...|       1.0|\n",
      "|(262144,[166027,2...|    0|[4.24081373896948...|[0.21204068694847...|       1.0|\n",
      "|(262144,[52879,52...|    0|[4.19317198950313...|[0.20965859947515...|       1.0|\n",
      "|(262144,[11941,21...|    0|[4.93801949703541...|[0.24690097485177...|       1.0|\n",
      "|(262144,[17734,68...|    0|[4.24081373896948...|[0.21204068694847...|       1.0|\n",
      "|(262144,[67828,21...|    0|[4.24081373896948...|[0.21204068694847...|       1.0|\n",
      "|(262144,[21650,32...|    0|[4.56639929162774...|[0.22831996458138...|       1.0|\n",
      "|(262144,[21650,32...|    0|[4.56639929162774...|[0.22831996458138...|       1.0|\n",
      "|(262144,[52879,18...|    0|[4.19317198950313...|[0.20965859947515...|       1.0|\n",
      "|(262144,[146227,1...|    0|[4.34534324771223...|[0.21726716238561...|       1.0|\n",
      "|(262144,[68228,21...|    0|[4.24081373896948...|[0.21204068694847...|       1.0|\n",
      "|(262144,[67117,10...|    0|[4.24081373896948...|[0.21204068694847...|       1.0|\n",
      "|(262144,[26143,34...|    0|[5.61056787181614...|[0.28052839359080...|       1.0|\n",
      "|(262144,[86936,10...|    0|[4.24081373896948...|[0.21204068694847...|       1.0|\n",
      "|(262144,[34343,40...|    0|[4.64177889352203...|[0.23208894467610...|       1.0|\n",
      "|(262144,[52788,87...|    0|[4.24081373896948...|[0.21204068694847...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rftest.show(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cac1e663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6916807150328762\n",
      "Test Error = 0.3083192849671238\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(rftest)\n",
    "print(\"Accuracy = %s\" % (accuracy))\n",
    "print(\"Test Error = %s\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31756c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_and_labels = rftest.select(['prediction','label']).withColumn('label', F.col('label').cast(FloatType())).orderBy('prediction')\n",
    "preds_and_labels = preds_and_labels.select(['prediction','label'])\n",
    "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "print(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e193529c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassificationModel: uid=dtc_83579c1cfded, depth=5, numNodes=19, numClasses=2, numFeatures=262144,\n",
       " DecisionTreeClassificationModel: uid=dtc_62a257923ca4, depth=4, numNodes=9, numClasses=2, numFeatures=262144,\n",
       " DecisionTreeClassificationModel: uid=dtc_96a0d7155237, depth=5, numNodes=15, numClasses=2, numFeatures=262144,\n",
       " DecisionTreeClassificationModel: uid=dtc_84a5a786e85c, depth=4, numNodes=11, numClasses=2, numFeatures=262144,\n",
       " DecisionTreeClassificationModel: uid=dtc_8991e6bb84a7, depth=5, numNodes=27, numClasses=2, numFeatures=262144,\n",
       " DecisionTreeClassificationModel: uid=dtc_77d9cef2614f, depth=5, numNodes=11, numClasses=2, numFeatures=262144,\n",
       " DecisionTreeClassificationModel: uid=dtc_bf53e9d88f8b, depth=5, numNodes=13, numClasses=2, numFeatures=262144,\n",
       " DecisionTreeClassificationModel: uid=dtc_c51f85d4f2ca, depth=5, numNodes=15, numClasses=2, numFeatures=262144,\n",
       " DecisionTreeClassificationModel: uid=dtc_289a14674f42, depth=5, numNodes=19, numClasses=2, numFeatures=262144,\n",
       " DecisionTreeClassificationModel: uid=dtc_563fb007e0e8, depth=5, numNodes=13, numClasses=2, numFeatures=262144,\n",
       " DecisionTreeClassificationModel: uid=dtc_ab2f9a5057e6, depth=5, numNodes=15, numClasses=2, numFeatures=262144,\n",
       " DecisionTreeClassificationModel: uid=dtc_036c71db8173, depth=5, numNodes=13, numClasses=2, numFeatures=262144,\n",
       " DecisionTreeClassificationModel: uid=dtc_aee4736d1755, depth=4, numNodes=9, numClasses=2, numFeatures=262144,\n",
       " DecisionTreeClassificationModel: uid=dtc_aad255bc7ca5, depth=5, numNodes=11, numClasses=2, numFeatures=262144,\n",
       " DecisionTreeClassificationModel: uid=dtc_530f6efe3726, depth=5, numNodes=15, numClasses=2, numFeatures=262144,\n",
       " DecisionTreeClassificationModel: uid=dtc_05bca484d2c5, depth=4, numNodes=19, numClasses=2, numFeatures=262144,\n",
       " DecisionTreeClassificationModel: uid=dtc_bc5fcaa50109, depth=5, numNodes=27, numClasses=2, numFeatures=262144,\n",
       " DecisionTreeClassificationModel: uid=dtc_8c8f9e5a144e, depth=5, numNodes=19, numClasses=2, numFeatures=262144,\n",
       " DecisionTreeClassificationModel: uid=dtc_18eaa188f530, depth=4, numNodes=11, numClasses=2, numFeatures=262144,\n",
       " DecisionTreeClassificationModel: uid=dtc_9f473d6e4ea2, depth=4, numNodes=9, numClasses=2, numFeatures=262144]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfModel.trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f839c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = LinearSVCModel.load(\"svm_spark.model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "37b30b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVCModel: uid=LinearSVC_ed819e61f2fc, numClasses=2, numFeatures=37120"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c0b8324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded.transform(test).select(\"label\", \"prediction\").write.csv(\"svmTest.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
